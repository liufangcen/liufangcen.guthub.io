---
title: ABiUNet
key: a-2021-08-18
typora-root-url: ..
tags:
  - Transformer
  - Saliency Object Detection
---



[论文地址](https://arxiv.org/pdf/2108.07851.pdf)

# Motivation

现有的显著性检测方法分成两类，一种采用CNN全卷积，缺点在于CNN只利用网络加深来获取较大的感受野，缺乏对全局上下文信息的直接描述；另一种方式是直接利用Transformer来进行全局信息的提取，缺点是损失了局部块内部细节信息的细粒度提取。因此本文结合CNN和Transformer同时对全局信息和局部信息进行建模，提出了一个非对称的双向UNet。

# Method

* 列举了本文与其他编解码器的区别

![](/figures/encoder-decoders.png)

* 本文的具体结构

  * 建立了两个对应的encoder和decoder路径，分别用Transformer和CNN进行特征提取
  * 从1/4分辨率开始进行特征交互，每个block的输入对每一个分辨率的transformer和CNN的特征进行concatenate
  * 在上采样路径中，首先在每个分支结构中利用channel attention进行重要性选择，然后将transformer经过CA的结果输入CNN的decoder再次进行特征交互，上述两个步骤能够保证在编解码过程中特征都具有全局和局部的信息。

  ![](/figures/ABiUNet.png)

